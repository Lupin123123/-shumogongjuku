{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable,function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class computeRNN(nn.Module):\n",
    "    def __init__(self,in_feature,hidden_size,n_class):\n",
    "        super(computeRNN, self).__init__()\n",
    "        self.in_feature=in_feature\n",
    "        self.hidden_size=hidden_size\n",
    "        self.n_class=n_class\n",
    "        self.in2hidden=nn.Linear(in_feature+self.hidden_size,self.hidden_size)\n",
    "        self.hidden2out=nn.Linear(self.hidden_size,self.n_class)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "\n",
    "    ##此处input的尺寸为[seq_len,batch,in_feature]\n",
    "    def forward(self,input,pre_state):\n",
    "        T=input.shape[0]\n",
    "        batch=input.shape[1]\n",
    "        # a=Variable(torch.zeros(T,batch,self.hidden_size))             #a-> [T,hidden_size]\n",
    "        # o=Variable(torch.zeros(T,batch,self.n_class))                 #o ->[T,n_class]\n",
    "        predict_y=Variable(torch.zeros(T,batch,self.n_class))\n",
    "        # pre_state = Variable(torch.zeros(batch, self.hidden_size))  # pre_state=[batch,hidden_size]\n",
    "\n",
    "\n",
    "        if pre_state is None:\n",
    "            pre_state = Variable(torch.zeros(batch, self.hidden_size))  # hidden ->[batch,hidden_size]\n",
    "\n",
    "        for t in range(T):\n",
    "            # input:[T,batch,in_feature]\n",
    "            tmp = torch.cat((input[t], pre_state), 1)  #  [batch,in_feature]+[batch,hidden_size]-> [batch,hidden_size+in_featue]\n",
    "            a=self.in2hidden(tmp)                      #  [batch,hidden_size+in_feature]*[hidden_size+in_feature,hidden_size] ->[batch,hidden_size]\n",
    "            hidden = self.tanh(a)\n",
    "\n",
    "            #这里不赋值的话就没有代表隐层向前传递\n",
    "            pre_state=hidden\n",
    "\n",
    "            o = self.hidden2out(hidden)  # [batch,hidden_size]*[hidden_size,n_class]->[batch,n_class]\n",
    "            #由于此次是一个单分类问题，因此不用softmax函数\n",
    "            if self.n_class ==1:\n",
    "                predict_y[t]=torch.sigmoid(o)\n",
    "            else:\n",
    "                predict_y[t] = self.softmax(o)\n",
    "\n",
    "\n",
    "        return predict_y, hidden\n",
    "\n",
    "input_size=2       #一个序列的长度,也就是输入特征数\n",
    "n_hidden = 12      #隐层神经元数目\n",
    "target_size = 1     #输出的尺寸\n",
    "rnn = computeRNN(in_feature=input_size,hidden_size=n_hidden,n_class=target_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练集\n",
    "file_path = r\"Attachment1-The historical weekly price of Qinhuangtao Port Steam Coal.xlsx\"\n",
    "data_csv = pd.read_excel(file_path, usecols=[1], header=3)\n",
    "data_csv=data_csv.dropna()\n",
    "data_set=data_csv.values\n",
    "data_set=data_set.astype('float32')\n",
    "max_value = np.max(data_set)\n",
    "scalar = max_value\n",
    "data_set = list(map(lambda x: x / scalar, data_set))\n",
    "# print(data_set)\n",
    "\n",
    "def create_dataset(dataset, look_back=2):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        a = dataset[i:(i + look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 创建好输入输出\n",
    "data_X, data_Y = create_dataset(data_set)\n",
    "# print(data_X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(466, 2, 1)\n",
      "(466, 1)\n",
      "(201, 2, 1)\n",
      "(201, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 932 into shape (3,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14436/4000675569.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtrain_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mtrain_Y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 932 into shape (3,2)"
     ]
    }
   ],
   "source": [
    "# 划分训练集和测试集，70% 作为训练集\n",
    "train_size = int(len(data_X) * 0.7)\n",
    "test_size = len(data_X) - train_size\n",
    "train_X = data_X[:train_size]\n",
    "train_Y = data_Y[:train_size]\n",
    "test_X = data_X[train_size:]\n",
    "test_Y = data_Y[train_size:].astype('float32')\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_Y.shape)\n",
    "\n",
    "train_X = train_X.reshape(-1,3, look_back)\n",
    "train_Y = train_Y.reshape(-1,3, 1)\n",
    "test_X = test_X.reshape(-1,1, 2)\n",
    "\n",
    "train_x = Variable(torch.from_numpy(train_X))\n",
    "train_y = Variable(torch.from_numpy(train_Y))\n",
    "test_x = Variable(torch.from_numpy(test_X))\n",
    "print(train_x[0])\n",
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer=optim.Adam(rnn.parameters(),lr=0.016)\n",
    "loss_fun=nn.MSELoss()\n",
    "\n",
    "num_epoch=1000\n",
    "# print(len(train_x))\n",
    "#\n",
    "for epoch in range(num_epoch):\n",
    "    state=None\n",
    "    out, state = rnn(train_x, state)\n",
    "    loss=loss_fun(out,train_y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 100 == 0:  # 每 100 次输出结果\n",
    "        # print('Epoch: {}, Loss: {:.5f}'.format(epoch + 1, loss.data[0]))\n",
    "        print(loss.size())\n",
    "    # state = None\n",
    "# #\n",
    "rnn.eval()\n",
    "hidden1=None\n",
    "out2,_=rnn(train_x,hidden1)\n",
    "plt.plot(out2.data.numpy().reshape(99,1))\n",
    "plt.plot(train_Y.reshape(99,1))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model=computeRNN(2,3,1)\n",
    "dummy_input = Variable(torch.randn(2,1,2))   #[torch.FloatTensor of size Nxinput_size],成员都是0\n",
    "# print(dummy_input)\n",
    "dummy_hidden=None\n",
    "output,dummy_hidden = model(dummy_input,dummy_hidden)        #得到[seq_num*target_size],[1*128]\n",
    "# print(output)\n",
    "# with SummaryWriter(comment='RNN') as w:\n",
    "#     w.add_graph(model, (dummy_input,dummy_hidden,))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
