{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from itertools import chain\n",
    "from scipy.interpolate import make_interp_spline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LSTM_PATH = r'./1.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据并标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pd.read_excel(path, header=1)\n",
    "    columns = df.columns\n",
    "    MAX = list(np.zeros(5))\n",
    "    MIN = list(np.zeros(5))\n",
    "    \n",
    "    df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    for i in range(3, 4):\n",
    "        print(np.max(df[columns[i]]))\n",
    "        print(np.min(df[columns[i]]))\n",
    "        MAX.append(np.max(df[columns[i]]))\n",
    "        MIN.append(np.min(df[columns[i]]))\n",
    "        df[columns[i]] = (df[columns[i]] - MIN[-1]) / (MAX[-1] - MIN[-1])\n",
    "    return df, MAX[0], MIN[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995.0\n",
      "365.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp/ipykernel_14204/2780498831.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df.fillna(df.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "path = r'附件1-秦皇岛港动力煤历史价格.xlsx'\n",
    "df_tmp, m_, n_ = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 30\n",
    "num = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, m, n = load_data()\n",
    "load = data[data.columns[1]]\n",
    "load = load.tolist()\n",
    "data = data.values.tolist()\n",
    "len(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = []\n",
    "for i in range(0, len(data) - 24 - num, num):\n",
    "    train_seq = []\n",
    "    train_label = []\n",
    "    for j in range(i, i + 24):\n",
    "        x = [load[j]]\n",
    "        for c in range(2, 8):\n",
    "            x.append(data[j][c])\n",
    "        train_seq.append(x)\n",
    "    for j in range(i + 24, i + 24 + num):\n",
    "        train_label.append(load[j])\n",
    "    train_seq = torch.FloatTensor(train_seq)\n",
    "    train_label = torch.FloatTensor(train_label).view(-1)\n",
    "    seq.append((train_seq, train_label))\n",
    "\n",
    "Dtr = seq[0:int(len(seq) * 0.7)]\n",
    "Dte = seq[int(len(seq) * 0.7):len(seq)]\n",
    "\n",
    "train_len = int(len(Dtr) / batch_size) * batch_size\n",
    "test_len = int(len(Dte) / batch_size) * batch_size\n",
    "Dtr, Dte = Dtr[:train_len], Dte[:test_len]\n",
    "\n",
    "train = MyDataset(Dtr)\n",
    "test = MyDataset(Dte)\n",
    "\n",
    "Dtr = DataLoader(dataset=train, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "Dte = DataLoader(dataset=test, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, batch_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.num_directions = 1\n",
    "        self.batch_size = batch_size\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, self.num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        c_0 = torch.randn(self.num_directions * self.num_layers, self.batch_size, self.hidden_size).to(device)\n",
    "        # print(input_seq.size())\n",
    "        seq_len = input_seq.shape[1]\n",
    "        # input(batch_size, seq_len, input_size)\n",
    "        input_seq = input_seq.view(self.batch_size, seq_len, self.input_size)\n",
    "        # output(batch_size, seq_len, num_directions * hidden_size)\n",
    "        output, _ = self.lstm(input_seq, (h_0, c_0))\n",
    "        # print('output.size=', output.size())\n",
    "        # print(self.batch_size * seq_len, self.hidden_size)\n",
    "        output = output.contiguous().view(self.batch_size * seq_len, self.hidden_size)  # (5 * 30, 64)\n",
    "        pred = self.linear(output)  # pred()\n",
    "        # print('pred=', pred.shape)\n",
    "        pred = pred.view(self.batch_size, seq_len, -1)\n",
    "        pred = pred[:, -1, :]\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size, hidden_size, num_layers, output_size = 7, 64, 1, num\n",
    "\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size, batch_size=batch_size).to(device)\n",
    "\n",
    "loss_function = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
    "    \n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    cnt = 0\n",
    "    print('当前', i)\n",
    "    for (seq, label) in Dtr:\n",
    "        cnt += 1\n",
    "        seq = seq.to(device)\n",
    "        label = label.to(device)\n",
    "        print(seq.size())\n",
    "        y_pred = model(seq)\n",
    "        loss = loss_function(y_pred, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if cnt % 100 == 0:\n",
    "            print('epoch', i, ':', cnt - 100, '~', cnt, loss.item())\n",
    "state = {'model': model.state_dict(), 'optimizer': optimizer.state_dict()}\n",
    "torch.save(state, LSTM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX = m\n",
    "MIN = n\n",
    "    \n",
    "pred = []\n",
    "y = []\n",
    "\n",
    "input_size, hidden_size, num_layers, output_size = 7, 64, 1, num\n",
    "model = LSTM(input_size, hidden_size, num_layers, output_size, batch_size=batch_size).to(device)\n",
    "model.load_state_dict(torch.load(LSTM_PATH)['model'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for (seq, target) in Dte:\n",
    "    target = list(chain.from_iterable(target.data.tolist()))\n",
    "    y.extend(target)\n",
    "    seq = seq.to(device)\n",
    "    # print(seq.size())\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(seq)\n",
    "        print(seq.size())\n",
    "        y_pred = list(chain.from_iterable(y_pred.data.tolist()))\n",
    "        # print(len(y_pred))\n",
    "        pred.extend(y_pred)\n",
    "\n",
    "y, pred = np.array([y]), np.array([pred])\n",
    "y = (MAX - MIN) * y + MIN\n",
    "pred = (MAX - MIN) * pred + MIN\n",
    "# print('accuracy:', (y, pred))\n",
    "# print(len(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.shape)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = 100\n",
    "lim = y.shape[1] - days \n",
    "x = [i for i in range(1, days+1)]\n",
    "\n",
    "x_smooth = np.linspace(np.min(x), np.max(x), 900)\n",
    "y_smooth = make_interp_spline(x, y.T[-days:])(x_smooth)\n",
    "\n",
    "plt.plot(x_smooth, y_smooth, c='green', marker='*', ms=1, alpha=0.75, label='true')\n",
    "\n",
    "y_smooth = make_interp_spline(x, pred.T[-days:])(x_smooth)\n",
    "plt.plot(x_smooth, y_smooth, c='red', marker='o', ms=1, alpha=0.75, label='pred')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = []\n",
    "for j in range(len(data)-24*batch_size, len(data)):\n",
    "    x = [load[j]]\n",
    "    for c in range(2, 8):\n",
    "        x.append(data[j][c])\n",
    "    input_seq.append(x)\n",
    "input_seq = torch.FloatTensor(input_seq)\n",
    "\n",
    "print(input_seq.size())\n",
    "input_seq = input_seq.reshape(batch_size, 24, 7)\n",
    "\n",
    "# xxx = torch.rand(30,24,7)\n",
    "# print(xxx.size())\n",
    "output = model(input_seq)\n",
    "output = (MAX - MIN) * output + MIN\n",
    "output[-1]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
